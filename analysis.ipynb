{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5e2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionmnist_data_rtime = [\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.9027},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.9006},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.8908},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.9012},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.8997},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.896},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.9005},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.8987},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.8968},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.8978},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.8974},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.8938},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.8976},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.8968},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.8953},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.894},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.8922},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.8938},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.8982},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.86},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.7664},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.9023},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.8966},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.8975},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.8987},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.8844},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.8978},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.901},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.8982},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.8972},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.8949},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.8793},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.879},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.8958},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.8932},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.8981},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.7323},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.7121},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.7071},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.9028},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.8963},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.8982},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.8057},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.7584},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.8621},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.899},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.9002},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.8962},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.8666},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.879},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.8913},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.8923},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.8953},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.894},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.711},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.7096},\n",
    "  {\"total_clients\": 4, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.709},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.9027},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.8974},\n",
    "  {\"total_clients\": 4, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.8948},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.7099},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.7113},\n",
    "  {\"total_clients\": 5, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.8298},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.8981},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.8996},\n",
    "  {\"total_clients\": 5, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.8957},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.7117},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.7222},\n",
    "  {\"total_clients\": 6, \"rounds\": 1, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.7069},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.8922},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.8909},\n",
    "  {\"total_clients\": 6, \"rounds\": 2, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.8881}\n",
    "]\n",
    "\n",
    "fashionmnist_data = [\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.914},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.913},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.9132},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.9117},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.91},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.9118},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 0, \"accuracy\": 0.9101},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 0, \"accuracy\": 0.9067},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 0, \"accuracy\": 0.9078},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.9104},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.9092},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.9084},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.9108},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.9093},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.9058},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 1, \"accuracy\": 0.9115},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 1, \"accuracy\": 0.9072},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 1, \"accuracy\": 0.9094},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.8976},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.908},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.9096},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.9042},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.9039},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.8959},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 2, \"accuracy\": 0.9062},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 2, \"accuracy\": 0.9045},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 2, \"accuracy\": 0.9028},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.7859},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.8727},\n",
    "  {\"total_clients\": 5, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.9011},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.8955},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.9018},\n",
    "  {\"total_clients\": 7, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.9049},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 100, \"byzantine_clients\": 3, \"accuracy\": 0.9063},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 80, \"byzantine_clients\": 3, \"accuracy\": 0.8932},\n",
    "  {\"total_clients\": 10, \"rounds\": 5, \"clients_per_round_percent\": 70, \"byzantine_clients\": 3, \"accuracy\": 0.8986}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ecd7e",
   "metadata": {},
   "source": [
    "# Analisi all'aumento del numero di nodi totali nei vari scenari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a46615e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_client_selection(client_selection, ds, num_clients, rounds) -> list[list[dict[str, any]]]:\n",
    "    cs = \\\n",
    "    [\n",
    "        [\n",
    "            {\n",
    "                \"Accuracy\": x[\"accuracy\"], \n",
    "                \"Byzantine\": x[\"byzantine_clients\"],\n",
    "                \"Total Clients\": x[\"total_clients\"],\n",
    "                \"Rounds\": x[\"rounds\"]\n",
    "            }\n",
    "            for x in ds\n",
    "            if x[\"total_clients\"] == total and \n",
    "            x[\"rounds\"] == rnd and \n",
    "            x[\"clients_per_round_percent\"] == client_selection\n",
    "        ]\n",
    "        for total in num_clients\n",
    "        for rnd in rounds\n",
    "    ]\n",
    "\n",
    "    cs.sort(key=lambda x : x[0]['Byzantine'])\n",
    "\n",
    "    return cs\n",
    "\n",
    "def get_seq(data: list[list[dict[str, any]]]) -> list[str]:\n",
    "    return [\n",
    "        \"\\n\" + str(group[0]['Total Clients']) + \" clients, \" + str(group[0]['Rounds']) + \" rounds: \" +\n",
    "        ' -> '.join([str(x['Accuracy']) for x in group])\n",
    "        for group in data\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_performance_decrease(client_selection, ds, num_clients, rounds):\n",
    "    cs = get_by_client_selection(client_selection, ds, num_clients, rounds)\n",
    "    seq = get_seq(cs)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89d41ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 clients, 1 rounds: 0.9027 -> 0.8982 -> 0.7323 -> 0.711\n",
      "\n",
      "4 clients, 2 rounds: 0.9012 -> 0.9023 -> 0.9028 -> 0.9027\n",
      "\n",
      "5 clients, 1 rounds: 0.9005 -> 0.8987 -> 0.8057 -> 0.7099\n",
      "\n",
      "5 clients, 2 rounds: 0.8978 -> 0.901 -> 0.899 -> 0.8981\n",
      "\n",
      "6 clients, 1 rounds: 0.8976 -> 0.8949 -> 0.8666 -> 0.7117\n",
      "\n",
      "6 clients, 2 rounds: 0.894 -> 0.8958 -> 0.8923 -> 0.8922\n"
     ]
    }
   ],
   "source": [
    "for x in get_performance_decrease(100, fashionmnist_data_rtime, [4,5,6], [1, 2]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ffde2",
   "metadata": {},
   "source": [
    "\n",
    "4 clients, 1 rounds: 0.9027 -> 0.8982 -> 0.7323 -> 0.711\n",
    "L'abbattimento maggiore delle performance si ha introducento il secondo nodo bizantino\n",
    "\n",
    "4 clients, 2 rounds: 0.9012 -> 0.9023 -> 0.9028 -> 0.9027\n",
    "Abbattimento praticamente nullo\n",
    "\n",
    "5 clients, 1 rounds: 0.9005 -> 0.8987 -> 0.8057 -> 0.7099\n",
    "Abbattimento delle performance minore rispetto al caso precedente ma comunque significativo: 9% all'introduzione del secondo nodo bizantino, 10% al terzo.\n",
    "\n",
    "5 clients, 2 rounds: 0.8978 -> 0.901 -> 0.899 -> 0.8981\n",
    "Abbattimento praticamente nullo \n",
    "\n",
    "6 clients, 1 rounds: 0.8976 -> 0.8949 -> 0.8666 -> 0.7117\n",
    "Prestazioni leggermente più basse inizialmente, ma più robusto. Solo al terzo nodo bizantino si ha un abbattimento significativo delle performance.\n",
    "\n",
    "6 clients, 2 rounds: 0.894 -> 0.8958 -> 0.8923 -> 0.8922\n",
    "Abbattimento praticamente nullo\n",
    "\n",
    "L'aumento del numero di round non sembra influenzare le performance, anzi, sembra migliorare la robustezza del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e6be831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 clients, 1 rounds: 0.9006 -> 0.86 -> 0.7121 -> 0.7096\n",
      "\n",
      "4 clients, 2 rounds: 0.8997 -> 0.8966 -> 0.8963 -> 0.8974\n",
      "\n",
      "5 clients, 1 rounds: 0.8987 -> 0.8844 -> 0.7584 -> 0.7113\n",
      "\n",
      "5 clients, 2 rounds: 0.8974 -> 0.8982 -> 0.9002 -> 0.8996\n",
      "\n",
      "6 clients, 1 rounds: 0.8968 -> 0.8793 -> 0.879 -> 0.7222\n",
      "\n",
      "6 clients, 2 rounds: 0.8922 -> 0.8932 -> 0.8953 -> 0.8909\n"
     ]
    }
   ],
   "source": [
    "for x in get_performance_decrease(80, fashionmnist_data_rtime, [4,5,6], [1, 2]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ebe87",
   "metadata": {},
   "source": [
    "4 client, 1 round -> 0.9006, 0.86, 0.7121, 0.7096   \n",
    "L'abbattimento maggiore delle performance si ha introducento il secondo nodo bizantino\n",
    "\n",
    "5 client, 1 round -> 0.8987, 0.8844, 0.7584, 0.7113 \n",
    "L'abbattimento maggiore delle performance si ha introducento il secondo nodo bizantino\n",
    "\n",
    "6 client, 1 round -> 0.8968, 0.8793, 0.879, 0.7222 \n",
    "Prestazioni leggermente più basse inizialmente, ma più robusto. Solo al terzo nodo bizantino si ha un abbattimento significativo delle performance.\n",
    "\n",
    "4 client, 2 round -> 0.8997, 0.8966, 0.8963, 0.8974 \n",
    "Abbattimento praticamente nullo\n",
    "\n",
    "5 client, 2 round -> 0.8974, 0.8982, 0.9002, 0.8996 \n",
    "Abbattimento praticamente nullo\n",
    "\n",
    "6 client, 2 round -> 0.8922, 0.8932, 0.8953, 0.8909 \n",
    "Abbattimento praticamente nullo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93f3dee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 clients, 1 rounds: 0.8908 -> 0.7664 -> 0.7071 -> 0.709\n",
      "\n",
      "4 clients, 2 rounds: 0.896 -> 0.8975 -> 0.8982 -> 0.8948\n",
      "\n",
      "5 clients, 1 rounds: 0.8968 -> 0.8978 -> 0.8621 -> 0.8298\n",
      "\n",
      "5 clients, 2 rounds: 0.8938 -> 0.8972 -> 0.8962 -> 0.8957\n",
      "\n",
      "6 clients, 1 rounds: 0.8953 -> 0.879 -> 0.8913 -> 0.7069\n",
      "\n",
      "6 clients, 2 rounds: 0.8938 -> 0.8981 -> 0.894 -> 0.8881\n"
     ]
    }
   ],
   "source": [
    "for x in get_performance_decrease(70, fashionmnist_data_rtime, [4,5,6], [1, 2]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda11b9",
   "metadata": {},
   "source": [
    "4 client, 1 round -> 0.8908, 0.7664, 0.7071, 0.709 \n",
    "L'abbattimento maggiore delle performance si ha introducento il secondo nodo bizantino\n",
    "\n",
    "5 client, 1 round -> 0.8968, 0.8978, 0.8621, 0.8298 \n",
    "L'abbattimento maggiore delle performance si ha introducento il secondo nodo bizantino\n",
    "\n",
    "6 client, 1 round -> 0.8953, 0.879, 0.8913, 0.7069 \n",
    "Prestazioni leggermente più basse inizialmente, ma più robusto. Solo al terzo nodo bizantino si ha un abbattimento significativo delle performance.\n",
    "\n",
    "4 client, 2 round -> 0.896, 0.8975, 0.8982, 0.8948 \n",
    "Abbattimento praticamente nullo\n",
    "\n",
    "5 client, 2 round -> 0.8938, 0.8972, 0.8962, 0.8957 \n",
    "Abbattimento praticamente nullo\n",
    "\n",
    "6 client, 2 round -> 0.8938, 0.8981, 0.894, 0.8881  \n",
    "Abbattimento praticamente nullo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b793ce",
   "metadata": {},
   "source": [
    "# Analisi all'aumentare del numero di round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fe54fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "\n",
    "def mean_at_byzantine_n(n, n_round, client_selection):\n",
    "    l = []\n",
    "\n",
    "    for x in fashionmnist_data_rtime:\n",
    "        if x['rounds'] == n_round and x['clients_per_round_percent'] == client_selection and x['byzantine_clients'] == n-1:\n",
    "            for y in fashionmnist_data_rtime:\n",
    "                if y['rounds'] == n_round and y['clients_per_round_percent'] == client_selection and y['byzantine_clients'] == n and x['total_clients'] == y['total_clients']:\n",
    "                    l.append(x['accuracy']-y['accuracy'])\n",
    "    return mean(l)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30e4d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance decrease: Single Round, Client Selection 100%\n",
      "First byzantine: 0.0029999999999999285\n",
      "Second byzantine: 0.09573333333333338\n",
      "Third byzantine: 0.09066666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean performance decrease: Single Round, Client Selection 100%\")\n",
    "print(\"First byzantine:\", mean_at_byzantine_n(1, 1, 100))\n",
    "print(\"Second byzantine:\", mean_at_byzantine_n(2, 1, 100))\n",
    "print(\"Third byzantine:\", mean_at_byzantine_n(3, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f563bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance decrease: Double Round, Client Selection 100%\n",
      "First byzantine: -0.0020333333333333314\n",
      "Second byzantine: 0.001666666666666668\n",
      "Third byzantine: 0.0003666666666667003\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean performance decrease: Double Round, Client Selection 100%\")\n",
    "print(\"First byzantine:\", mean_at_byzantine_n(1, 2, 100))\n",
    "print(\"Second byzantine:\", mean_at_byzantine_n(2, 2, 100))\n",
    "print(\"Third byzantine:\", mean_at_byzantine_n(3, 2, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a015266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance decrease: Single Round, Client Selection 80%\n",
      "First byzantine: 0.024133333333333378\n",
      "Second byzantine: 0.0914\n",
      "Third byzantine: 0.06879999999999997\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean performance decrease: Single Round, Client Selection 80%\")\n",
    "print(\"First byzantine:\", mean_at_byzantine_n(1, 1, 80))\n",
    "print(\"Second byzantine:\", mean_at_byzantine_n(2, 1, 80))\n",
    "print(\"Third byzantine:\", mean_at_byzantine_n(3, 1, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd5e48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance decrease: Double Round, Client Selection 80%\n",
      "First byzantine: 0.0004333333333333596\n",
      "Second byzantine: -0.0012666666666666753\n",
      "Third byzantine: 0.001300000000000005\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean performance decrease: Double Round, Client Selection 80%\")\n",
    "print(\"First byzantine:\", mean_at_byzantine_n(1, 2, 80))\n",
    "print(\"Second byzantine:\", mean_at_byzantine_n(2, 2, 80))\n",
    "print(\"Third byzantine:\", mean_at_byzantine_n(3, 2, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa5d044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance decrease: Single Round, Client Selection 70%\n",
      "First byzantine: 0.04656666666666668\n",
      "Second byzantine: 0.0275666666666667\n",
      "Third byzantine: 0.0716\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean performance decrease: Single Round, Client Selection 70%\")\n",
    "print(\"First byzantine:\", mean_at_byzantine_n(1, 1, 70))\n",
    "print(\"Second byzantine:\", mean_at_byzantine_n(2, 1, 70))\n",
    "print(\"Third byzantine:\", mean_at_byzantine_n(3, 1, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "872228d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance decrease: Double Round, Client Selection 70%\n",
      "First byzantine: -0.003066666666666625\n",
      "Second byzantine: 0.0014666666666666532\n",
      "Third byzantine: 0.00326666666666664\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean performance decrease: Double Round, Client Selection 70%\")\n",
    "print(\"First byzantine:\", mean_at_byzantine_n(1, 2, 70))\n",
    "print(\"Second byzantine:\", mean_at_byzantine_n(2, 2, 70))\n",
    "print(\"Third byzantine:\", mean_at_byzantine_n(3, 2, 70))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
